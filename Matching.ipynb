{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "import string\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Helper Functions\n",
    "\n",
    "Following codes define functions that are needed to load/parse Facebook data files, and transform the data.\n",
    "\n",
    "* `parse_json`: Read json files from the path. `file_end` argument is used to filter out the mistakenly submitted files.\n",
    "* `name_normal`: Normalize keywords in the data. (a) de-captitalize keywords, (b) delete punctuations, and (c) delete a single word initial in the middle (to delete middle names).\n",
    "* `expand_to_df`: Expand a dictionary that contains each R's data (key: user id / value: list of keywords from the data) into a regular Pandas data frame.\n",
    "\n",
    "IMPORTANT: `name_normal` is not applied to any of following codes to ensure the precision of the matching process. Should be applied later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_json(path, file_end):\n",
    "    path = path + '/'\n",
    "    json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith(file_end)]\n",
    "    \n",
    "    out = dict()\n",
    "    \n",
    "    for file in json_files[0:5]:\n",
    "        user_id = re.sub(file_end + \"$\", \"\", file)  # Filter files with a pariticular file end (e.g. \"_pages.json\")\n",
    "        full_file = path + file \n",
    "        \n",
    "        try:\n",
    "            with open(full_file, 'r', encoding='UTF-8') as f:\n",
    "                out[user_id] = json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return out\n",
    "\n",
    "translator=str.maketrans('','',string.punctuation)\n",
    "\n",
    "def name_normal(name):\n",
    "    out = name.lower().translate(translator)  # (a) De-capitalize, and (b) delete punctuations.\n",
    "    out = re.sub(\"\\s[A-Za-z]\\s\", \" \", out)    # (c) Delete single characters in the middle.\n",
    "    \" \".join(out.split())\n",
    "    \n",
    "    return out\n",
    "\n",
    "def expand_to_df(matched_keywords):\n",
    "    isin_keywords = dict()\n",
    "    \n",
    "    potent_keywords = list(set().union(*matched_keywords.values())) # Get all the keywords that appeared in the data at least once.\n",
    "    \n",
    "    for key, keywords in matched_keywords.items():\n",
    "        isin_keywords[key] = [item in keywords for item in potent_keywords] # Expand a list of keywords into a seriese of TRUE/FALSE.\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(isin_keywords, orient='index', columns = potent_keywords)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data\n",
    "## 2.1. Load and Parse JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_json = parse_json(\"data/Qualtrics panel data/Q50\", \"_pages.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code transforms the loaded liked pages to a dictionary with keys being user id's and values being lists of liked pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Index = dict()\n",
    "\n",
    "for key, value in dt_json.items():\n",
    "    Index[key] = list()\n",
    "    if 'page_likes' in value.keys():\n",
    "        test_key = value['page_likes'][0].keys()\n",
    "        \n",
    "        if 'data' in test_key:        # This if clause is needed to load two different formats of JSON data.\n",
    "            for item in value['page_likes']:\n",
    "                Index[key].append(item['data'][0]['name'])\n",
    "        else:\n",
    "            for item in value['page_likes']:\n",
    "                Index[key].append(item['name'])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_ads = parse_json(\"data/Qualtrics panel data/Q52\", \"_ads_interests.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code transforms the loaded advertising categories to a dictionary with keys being user id's and values being lists of advertising categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ads_topics = dict()\n",
    "\n",
    "for key, value in dt_ads.items():\n",
    "    ads_topics[key] = list()\n",
    "    \n",
    "    try:\n",
    "        if 'topics' in value.keys():\n",
    "            for item in value['topics']:\n",
    "                ads_topics[key].append(item)\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Load Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Takes about a minute.\n",
    "dic = pd.read_excel(\"Civic customization Dictionary 02-10-19.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the loaded MS Excel filte to a long list of keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic = dic['Full Name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Matching\n",
    "## 3.1.  Perfect Matching\n",
    "Perfect matching simply converts two lists of keywords (a dictionary & R's keywords) into sets, and obtain intersection. The outcome is a dictionary with keys being user id and values being matched keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def perfect_matching(dict_keyword, dic):\n",
    "    matched_keywords = dict()\n",
    "    dic = set(dic)  # Convert a dictionary to a set\n",
    "    \n",
    "    for key, value in dict_keyword.items():\n",
    "        \n",
    "        matched_keywords[key] = list(set(value) & dic) # (a) Convert a list of keywords into a set, and (b) Get the intersection. \n",
    "    \n",
    "    return matched_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Index_perfect = perfect_matching(Index, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ads_topics_perfect = perfect_matching(ads_topics, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_Index_perfect = expand_to_df(Index_perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_Index_perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ads_topics_perfect = expand_to_df(ads_topics_perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ads_topics_perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.2.  Fuzzy Matching\n",
    "Fuzzy matching is harder: (a) It breaks every keyword and dictionary entry into a list of words (e.g. \"Donald Trump\" -> [\"Donald\", \"Trump\"]), and (b) if the list of words is a subset of any list of words in the dictionary (e.g. a keyword in the data: [\"Donald\", \"Trump\"] <= an entry from the dictionary: [\"President\", \"Donald\", \"Trump\"]), then the keyword is considered as matched.  \n",
    "\n",
    "This process cannot entertain the efficient Python set operation to match anymore. This algorithm simply compare every single keyword in the data with every single entry in the dictionary sequentially. Suppose that 300 respondents have 500 keywords on average, and that the dictionary has 160,000 entries. Then the opertation is conduected 300 x 500 x 160,000 = 24 billion times. This is definitely where parallelizing can help reduce the computing time, but it hasn't been implemented yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fuzzy_matching(dict_keyword, dic):\n",
    "    matched_keywords = dict()\n",
    "    \n",
    "    for key, value in dict_keyword.items():  # For each respondent\n",
    "        matched_keywords[key] = list()\n",
    "        for liked_word in value:             # For each keyword in the data\n",
    "            for dic_word in dic:             # For each entry in the dictionary\n",
    "                if set(str(liked_word).split()) <= set(str(dic_word).split()):   # If a splitted keyword is a subset of a splitted entry  \n",
    "                    matched_keywords[key].append(liked_word)  # Then add the keyword in the matched keyword list\n",
    "                    break                                     # If the keyword was matched, stop matching with that keyword\n",
    "    \n",
    "    return matched_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fuzzy_matching(Index, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
